{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "UUpSV_S = np.loadtxt('./datasets/dSHR_BBPF_UUp_150_160_SV_norm.npy')\n",
    "UUpSV_U = np.loadtxt('./datasets/dSHR_BBPF_UUp_161_170_SV_norm.npy')\n",
    "UUpLV_S = np.loadtxt('./datasets/dSHR_BBPF_UUp_150_160__norm.npy')\n",
    "UUpLV_U = np.loadtxt('./datasets/dSHR_BBPF_UUp_161_170__norm.npy')\n",
    "\n",
    "UUpSV_S_scale = np.loadtxt('./datasets/dSHR_BBPF_UUp_150_160_SV_scale.txt')\n",
    "UUpSV_U_scale = np.loadtxt('./datasets/dSHR_BBPF_UUp_161_170_SV_scale.txt')\n",
    "UUpLV_S_scale = np.loadtxt('./datasets/dSHR_BBPF_UUp_150_160__scale.txt')\n",
    "UUpLV_U_scale = np.loadtxt('./datasets/dSHR_BBPF_UUp_161_170__scale.txt')\n",
    "\n",
    "UUpSV_S_means = np.loadtxt('./datasets/dSHR_BBPF_UUp_150_160_SV_means.txt')\n",
    "UUpSV_U_means = np.loadtxt('./datasets/dSHR_BBPF_UUp_161_170_SV_means.txt')\n",
    "UUpLV_S_means = np.loadtxt('./datasets/dSHR_BBPF_UUp_150_160__means.txt')\n",
    "UUpLV_U_means = np.loadtxt('./datasets/dSHR_BBPF_UUp_161_170__means.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = 9 # GUp: 12, UUp: 9\n",
    "no = 1  # GUp: 1 , UUp: 1\n",
    "dt = UUpLV_S\n",
    "sc = UUpLV_S_scale\n",
    "mn = UUpLV_S_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dt)\n",
    "\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b16208",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8*dt.shape[0])\n",
    "x_train = dt[0:split,0:-1]\n",
    "y_train = dt[0:split,-1]\n",
    "\n",
    "x_val = dt[split+1:-1,0:-1]\n",
    "y_val = dt[split+1:-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77be7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square( y_true - y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(nneurons, nfeat, nlab, nlayers):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    input_layer = tf.keras.layers.Input(shape=(nfeat))\n",
    "\n",
    "    x = tf.keras.layers.Dense(nneurons, activation='relu', use_bias=True)(input_layer)\n",
    "    for i in range(1,nlayers):\n",
    "        x = tf.keras.layers.Dense(nneurons, activation='relu', use_bias=True)(x)\n",
    "        \n",
    "    output_layer = tf.keras.layers.Dense(nlab, activation='linear', use_bias=True)(x)\n",
    "        \n",
    "    model = tf.keras.models.Model(input_layer, output_layer)\n",
    "        \n",
    "    adam = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, \n",
    "                                           beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[coeff_determination])\n",
    "    model._name = f'model_n_{nneurons}_lay_{nlayers}'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [20, 40, 60]\n",
    "layers = [2, 3, 5, 7]\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath='ANN_checkpoints/ANN_M1_weight-{epoch:02d}.h5', \n",
    "                                                  monitor='val_loss', \n",
    "                                                  verbose=1, \n",
    "                                                  save_best_only=True, \n",
    "                                                  mode='min')\n",
    "\n",
    "repof = './ANN_M1_repo.txt'\n",
    "with open(repof, 'w') as f:\n",
    "    f.write('layer\\t neuron\\t train_cod\\t val_cod\\n')\n",
    "    for layer in layers:\n",
    "        for neuron in neurons:\n",
    "            model = Model(neuron, ni, no, layer)\n",
    "            history_callback = model.fit(x_train, y_train, epochs=500, batch_size=4096, \n",
    "                                    validation_data=[x_val, y_val], validation_batch_size=1024, \n",
    "                                    callbacks=[checkpoints])\n",
    "            indx = np.argmin(history_callback.history['val_loss'])\n",
    "            info = [history_callback.history['coeff_determination'][indx], \n",
    "                    history_callback.history['val_coeff_determination'][indx]]\n",
    "            f.write(f'{layer}\\t{neuron}\\t{info[0]}\\t{info[1]}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005df398",
   "metadata": {},
   "outputs": [],
   "source": [
    "repof = './ANN_M1_repo.txt'\n",
    "with open(repof, 'r') as f:\n",
    "    ls = f.read().splitlines()\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89edd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [20, 40, 60]\n",
    "layers = [2, 3, 5, 7]\n",
    "cod = np.array([[u.split('\\t')[2],u.split('\\t')[-1]] for u in ls[1:]])\n",
    "cod_20 = np.array([float(cod[3*i,0]) for i in range(4)])\n",
    "cod_40 = np.array([float(cod[3*i+1,0]) for i in range(4)])\n",
    "cod_60 = np.array([float(cod[3*i+2,0]) for i in range(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = [i for i in layers]\n",
    "plt.plot(xaxis, cod_20, 'rx')\n",
    "plt.plot(xaxis, cod_40, 'bx')\n",
    "plt.plot(xaxis, cod_60, 'gx')\n",
    "#plt.ylim([0.6, 1.05])\n",
    "plt.rcParams.update({'font.size':13})\n",
    "plt.xlabel('Number of hidden layers')\n",
    "plt.ylabel(r'r2')\n",
    "plt.legend(['N=20', 'N=40', 'N=60'], ncol=2, loc='lower right')\n",
    "#plt.savefig('ANN_M1_hyperparam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62417f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc187b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa96380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
